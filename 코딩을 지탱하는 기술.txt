코딩을 지탱하는 기술

2020.02.28

10. 병행 처리

10.1 병행 처리란?

복수의 처리를 시간축 상에 오버랩에서 실행하는 것을 병행 처리라고 한다.

옛날 컴퓨터인 EDSAC 등에서는 프로그램을 입력 후 계산을 실행하면 이후는 계산이
끝날 때까지 기다리는 수 밖에 없었다. 하나의 프로그램 처리가 시작해서 끝날 때까지
컴퓨터는 해당 처리만을 할 수 있었다.

* 프로그래밍 언어에 있어서의 병행성과 하드웨어의 병렬성이란 상호간에 독립된 개념이다.
즉, 병렬성은 하드웨어 측면의 개념이다. 반면 프로그래밍 측면의 병행성의 주안점은 
프로세스나 스레드 등의 개념이다.

편리한 병행 처리를 실현하기 위해 프로세스나 스레드 등의 개념이 만들어졌다.
또한 병행 처리가 원인이 되어 새로운 문제를 일으키게 되자 그 대안 책으로 락이나 
파이버 등의 개념이 발명되었다.

10.2 잘게 분할해서 실행한다.

한 번에 하나의 처리만 실행하는 것보다 복수 개의 처리를 동시에 실행하는 것이 편리하다.
하지만 실행하기 위한 회로(CPU)가 하나 밖에 없는데 어떻게 복수의 처리를 동시에 실행할 수 있는 것일까?

그것은 '사람이 눈치챌 수 없는 짧은 순간에 복수의 처리를 변경해가면서 실행'하기 때문이다.
어떤 순간에는 하나의 처리만 실행되지만, 사람의 눈에는 복수의 처리가 병행해서 동작하고 
있는 듯이 보인다.

이것이 병행 처리의 가장 중요한 개념으로, 사람의 눈으로 보면 프로그램이 계속 동작하고
있는 것처럼 보이지만 실제로는 잘게 분할해서 실행되고 있는 것이다. 

10.3 처리를 변경하는 2가지 방법

1. 협력적 멀티태스크
하나는 '타이밍이 좋은 시점에서 교대'하는 방법이다. 처리가 일단락되는 시점에 자발적으로
처리 교대를 하는 방법이다. 이 방법으로 구현된 멀티 태스크를 협력적 멀티태스크라고 한다.

이 방법에서는 어떤 처리가 '교대해도 좋다'라고 말하지 않고 계속 실행하면 다른 처리는
계속 기다려야 하는 문제점이 있다. 어디까지나 '모든 처리가 최적의 간격으로 교대한다'
는 신뢰 관계를 기반으로 성립하는 시스템이다.

2. 선점적 멀티태스크
다른 한 가지 방법은 '일정 시간에 교대'하는 것이다. 이 방법에서는 개별 프로그램과 
입장이 다른 프로그램(태스크 스케줄러)이 존재한다. 이 프로그램이 일정 시간마다
지금 실행되고 있는 처리를 강제적으로 중단시켜서 다른 프로그램이 실행될 수 있도록 한다.

이 방법으로 구현된 멀티태스크를 선점적 멀티태스크라고 한다. 선점적이란 '타인의 행동을
막기 위한'이란 의미다. 이 기법은 협력적 멀티태스크와 달리 '처리를 멈출 수 있는 프로그램의
협력' 없이도 강제적으로 처리를 중지시킬 수 있는 것이 특징이다.

10.4 경합 상태 방지법

경합 상태는 이 프로그램은 '스레드 세이프가 아니다'라고 표현한다.

경합 상태는 평행해서 동작하고 있는 2가지 처리 간에 경합 상태가 발생하기 위해서는
3가지 조건을 모두 만족해야 한다.
1. 2가지 처리가 변수를 공유하고 있다.
2. 적어도 하나의 처리가 그 변수를 변경한다.
3. 한쪽 처리가 한 단락 마무리 되기 전에, 다른 한쪽의 처리가 끼어들 가능성이 있다.

역으로 말하면, 이 3가지 조건 중 하나라도 제거할 수 있다면 병행 실행 시에도 안정된
프로그램을 만들수 있다.

공유하지 않는다 - 프로세스와 액터 모델
처음부터 아무것도 공유하지 않으면 1번은 발생하지 않기 때문에 경합 상태를 신경 쓸 필요가 없다.

프로세스에서는 메모리를 공유하지 않는다.
-----------------------------------------------
UNIX에서는 실행 중의 프로그램을 '프로세스'라고 부른다. 서로 다른 프로세스는 메모리를
공유하지 않는다. 때문에 복수의 프로그램이 메모리 상에서 경합 상태를 일으킬 일은 없다.
데이터베이스 접속, 파일 읽고 쓰기 등 무엇인가를 공유했을 때만 주의하면 된다.

'프로세스'라는 용어는 UNIX가 탄생하기 전부터 사용되고 있었으며 당시에는 메모리를
공유하고 있어서 지금의 '스레드'와 비슷했다.

UNIX에서는 프로세스 별로 '사용해도 좋은 메모리 영역'을 결정함으로, '다른 프로세스와
메모리를 공유하지 않는다'를 실현하는 구조를 채용했다.
-> 가상 주소 공간

공유하지 않는 접근법은 성공했을까?
----------------------------------------
UNIX는 '하나의 프로세스 안에서 병행해서 실행되는 처리는 하나'라는 구조였다.
즉 복수의 처리를 병행해서 실행하고 싶다면 복수의 프로세스를 구동해야 한다.
서로 다른 프로세스는 메모리를 공유하지 않지만, 이것은 즉 '병행 실행되는 처리는
메모리를 공유하지 않는다'는 것이다.

UNIX 출시 후 약 10년 후 '경량 프로세스'가 만들어진다. 이것은 메모리를 공유하는 
UNIX 이전 방식의 프로레스다. 이것이 나중에 '스레드'라고 불리게 되었다.

액터 모델
----------------------------------------
'메모리를 공유하지 않는다'는 설계 방침에서의 또 다른 흐름이 바로 액터 모델이다.
액터 모델은 1937년에 발표된 병행 처리를 표현하기 위한 모델이다.

병행해서 동작하는 복수의 처리가 정보를 교환하는 방법으로, '메모리를 공유한다'가 아닌
'메시지를 보낸다'를 제안했다.

사무 일을 보는 사람과 서류, 서류 상자로 예들 들자.
A가 책상 위에 서류를 펼쳐놓고 작업을 하고 있을 때 B가 A에 다른 일을 부탁한다고 
하는 상황이다. 서류가 펼쳐진 A의 책상에 B가 서류를 놓는다면 A의 작업에 방해가 될
것이다. 이것이 공유 메모리의 문제점이다. 한편, A의 작업이 한 단락 마무리 될 때까지
B가 옆에서 대기하면 B의 시간을 버리게 된다. 이것이 락의 문제점이다. 그렇지 않고
B가 A의 서류 상자에 서류를 넣고 자신의 자리로 돌아가는 것이 액터 모델이다.

처리는 비동기로 이루어진다. A가 서류 상자 안의 서류를 언제 처리할지 B는 모른다.
언제 처리가 끝나는지도 서류에 '끝나면 B에게 보내라'라고 써놓고 B가 자신의 서류 
상자에 A가 돌려보낸 것을 발견하고 나서야 '끝났구나'하고 알게 되는 것이다.

이런 특징이 잘 맞는 처리가 바로 메시지 교환이다. 트위터나 페이스북 등의 '대량의 
사용자 메시지를 취급한느 서비스'에서는 이 액터 모델이 적합한 처리가 많다.

변경하지 않는다 - const, val, Immutable

'메모리를 공유해도 변경하지 않으면 문제가 없다'는 2번에 대한 대응책도 있다.

모든 값이 변경 불가능한 Haskell이라는 언어가 있다.

한편, 보다 현실적인 타협안으로 '일부 변수를 변경할 수 없게 한다'는 구조를 가진
언어가 많이 있다. 예를 들어 C++에서는 const를 붙여서 변수 선언을 하면 변경할 
수 없는 변수가 된다. 또한 Scala에서는 var와 val의 2가지 변수 선언이 있어서, val로
선언한 것은 변경할 수 없다.

JAVA에서는 Mark Grand가 제안한 디자인 패턴의 하나인 Immutable 패턴이 자주 사용된다.
클래스에 private 필드를 만들어서 그것을 읽어내기 위해 getter 메소드를 만들지만, 
변경하기 위한 방법이 마련되어 있지 않아서 '읽는 것은 가능하나 변경은 안 된다'는 
상황을 구현할 수 있다.

끼어들지 않는다.
협력적 스레드 사용 - 파이버, 코루틴, 그린 스레드
-----------------------------------------------------------------------
스레드가 선점성을 가지고 끼어드는 원인이 되기 때문에 협력적 스레드를 만들면 된다는
생각이다. Ruby의 Fiber 클래스나 JavaScript의 제너레이터가 그 예다.

물론 협력적 멀티태스크이기 때문에 어떤 스레드가 CPU를 독점하면 다른 스레드의
처리가 멈춘다. 어디까지나 각 스레드가 협력적으로 최적의 순간을 맞춘다는 사실을 
전제로 하고 있다.

끼어들면 곤란해지는 처리에 표식을 붙인다 - 락, 뮤텍스, 세마포어
------------------------------------------------------------------------
 다른 한 가지 방법은 '지금 끼어들면 곤란해'라는 표식을 공유하는 것이다. 예를 들어,
어떤 메모리 값이 0이 아니면 이것은 '다른 스레드가 끼어들면 곤란한 처리를 하고 있어'
라고 정해 두는 것이다. 각 스레드는 '끼어들면 문제가 발생하는 처리'를 하기 전에, 우선
해당 메모리 값을 체크한다. 그 값이 0이면 처리를 실행해도 좋고, 0이 아니면 0으로 
바뀌기까지 기다렸다가 처리를 한다.

이 방법에는 여러 가지 기법이 있어서, 락, 뮤텍스, 세마포어 등 다양한 명칭이 있지만 
핵심 개념은 '사용중' 표식과 같다. 

'락'이라는 이름 때문에 '락을 걸어 두면 다른 사람이 들어올 수 없다'고 착각하기 쉽다.
하지만 실제는 '사용중'이라는 표식을 붙여둘 뿐, 표식을 확인하지 않고 실행하는 
스레드가 있으면 아무 소용이 없다. 처리 흐름의 일부 만을 협력적으로 양보하는 
구조라고 볼 수 있다.

'안에 들어갈 때 사용중이란 표식이 있는지 확인, 있으면 대기, 없으면 표식을 걸고 안
으로 들어간다'는 일련의 처리를 바르게 구현하는 것은 쉽지 않은 일이다. 예를 들어
if 문 등으로 만들면 '값을 확인한다'와 '0이면 1로 변환한다' 사이에 별도 처리가 끼어들
가능성이 발생한다. 다른 처리가 끼어들지 못하게 하기 위해 기계어의 '값 확인과 변경을
한 번에 실행하는 명령' 등을 사용할 필요가 생긴다. JAVA의 언어 처리계는 이 기능을
자체적으로 구현해서 채용했다. 이로 인해 JAVA 언어 사용자는 자신이 직접 고생하지 
않고도 'sychronized 블록'으로 감싸기만 하면 손쉽게 락을 걸 수 있게 되었다.

10.5 락의 문제점과 해결책

락의 문제점

교착 상태가 발생한다
--------------------------------------------
공유된 X와 Y를 변경하는 처리 A와 처리 B가 있다고 하자. A가 'X를 락시키고, Y를 락
시킨다'는 순서로 락을 걸어두고, B가 'Y를 락시키고, X를 락시킨다'는 순서로 락을 걸었
을 경우 시점에 따라선 문제가 발생한다. A가 X를 락하고 B가 Y를 락하는 상태에서 
서로가 상대방 락이 풀리는 것을 기다리게 된다.

이것이 교착 상태라고 불리는 현상이다. 이 문제를 방지하기 위해서 프로그래머는
프로그램 전체에서 락의 순서가 일관되도록 주의해야 한다. '무엇에 락을 걸어야 하는가'
뿐만 아니라, '어떤 순으로 락을 걸어야 하는가'도 파악해야 한다.

합성할 수 없다
--------------------------------------------
             X에서 2를 꺼냄             Y에 2를 추가한다
X 2 3     ------------------> X 3   -----------------------> X 3
Y 1                                Y 1                                 Y 1 2
                              어중간한 상태

스레드 세이프 라이브러리에서는 락 제어를 프로그래머가 챙기지 않아도 되도록, 내부에서
락을 사용해 '꺼내는 처리'나 '추가하는 처리'가 끼어들지 못하도록 한다. 하지만 이 락으로는
'X에서 빼내서 Y에 넣는다'는 2가지 명령의 사이에 끼어드는 것을 막을 수는 없다. 끼어
들기를 막기 위해서는 프로그래머가 2가지 처리를 묶는 새로운 락을 만들어서, X나 Y를
읽고 쓰는 모든 코드를 synchronized 블록 등으로 감싸지 않으면 안 된다.

트랜잭션 메모리
이 문제를 해결하려고 하는 것이 트랜잭션 메모리라는 접근법이다. 데이터베이스의 트랜
잭션 기법을 메모리에 적용한 것이다. 개념은 '실험적으로 해보고, 실패하면 처음부터 다시
고쳐서 하고, 성공하면 변경을 공유한다'이다. X나 Y를 직접 변경하는 것이 아니라, 일시적으로
별도 버전을 만들어서 그것을 변경하고 하나의 묶음 처리가 끝나면 반영하는 것이 포인트다.

읽는 처리를 할 때는 아직 일시적으로 만들어진 별도 버전의 변경이 원래 버전에 반영되지 않고,
다른 스레드가 보고 있는 상황은 'X에서 꺼낸다'의 앞 부분이다. 그래서 특별한 문제는
발생하지 않는다.

쓰는 처리가 끼어들면 일시적으로 만들어진 별도 버전은 버리고 다시 처음부터 시작한다.
이와 같이 락을 걸지 않아도 문제 없이 병행 처리가 가능하다. 단, 쓰는 처리의 빈도가 높을 
때는 '다시 고쳐서 하기' 작업이 다발해서 성능이 나빠진다.